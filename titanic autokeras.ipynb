{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic competition\n",
    "goal: create fast and submit to learn how to deal with Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general & data analysis imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# data preprocessing imports\n",
    "from sklearn import preprocessing\n",
    "#import category_encoders as ce\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model learning & evaluation imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv('train.csv')\n",
    "test_dataset=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.hist(figsize=(15,20));\n",
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_dataset, hue=\"Survived\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"SibSp\", y=\"Survived\", data=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Parch\", y=\"Survived\", data=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_dataset.corr(),annot=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dependent variable from train set to have the same structure as test set\n",
    "df_y=train_dataset['Survived'].copy()\n",
    "train_dataset.drop('Survived', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(source_df):\n",
    "    df=source_df.copy()\n",
    "    # Age to bins, NaN to separate bin\n",
    "    #df.Age.fillna(-1, inplace=True)\n",
    "    #age_bins=(-10,0,10,30,500)\n",
    "    #age_labels=('unk','upto10','upto30','above30')\n",
    "    #df.Age=pd.cut(df.Age, age_bins, labels=age_labels)\n",
    "    #cabin - keep first letter\n",
    "    df.Cabin.fillna('Unknown', inplace=True)\n",
    "    df.Cabin=df.Cabin.apply(lambda x: x[0])\n",
    "    # fare - divide by mean (~32)\n",
    "    df.Fare.fillna(df.Fare.median(), inplace=True)\n",
    "    #df.Fare=df.Fare.apply(lambda x: x/32)\n",
    "    # embarked - fillna\n",
    "    df.Embarked.fillna('U', inplace=True)\n",
    "    # SibSp, Parch - replace to binary\n",
    "    #df['SibSp']=df['SibSp'].apply(lambda x: 1 if (x==1)|(x==2) else 0)\n",
    "    #df['Parch']=df['Parch'].apply(lambda x: 1 if (x==1)|(x==2)|(x==3) else 0)\n",
    "    \n",
    "    #df['FamilySize']=df['SibSp']+df['Parch']+1\n",
    "    #df.SibSp=df.SibSp.apply(lambda x: int(x>0))\n",
    "    #df.Parch=df.Parch.apply(lambda x: int(x>0))\n",
    "    # df['Fam_label']=df.FamilySize.apply(Fam_label)\n",
    "    # ticket, name - drop\n",
    "    df=df.drop(['Ticket','Name','PassengerId'], axis=1)\n",
    "\n",
    "    #return preprocessed df\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=preprocess_data(test_dataset)\n",
    "df_train=preprocess_data(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df1, df2):\n",
    "    '''df1, df2 - train and test dataframes\n",
    "    return - modified df1, df2'''\n",
    "    \n",
    "    cat_features =['Sex','Pclass','Cabin','Embarked'] # features for categorization\n",
    "    onehot_features=['Cabin','Embarked','Age'] # features for onehot encoding\n",
    "    \n",
    "    # for each feature, use LabelEncoder on both dataframes\n",
    "    for f in cat_features:\n",
    "        l_encoder = preprocessing.LabelEncoder()\n",
    "        l_encoder.fit(df1[f])\n",
    "        df1[f]=l_encoder.transform(df1[f])\n",
    "        df2[f]=l_encoder.transform(df2[f])\n",
    "\n",
    "    # use OneHotEncoder on both dataframes\n",
    "    # oh_encoder = ce.OneHotEncoder(handle_unknown='ignore', cols=onehot_features,use_cat_names=True)\n",
    "    # df1=oh_encoder.fit_transform(df1)\n",
    "    # df2=oh_encoder.transform(df2)\n",
    "    \n",
    "    # drop manually featurez for \"unknown\" values\n",
    "    #df1.drop('Age_unk', axis=1, inplace=True)\n",
    "    #df2.drop('Age_unk', axis=1, inplace=True)\n",
    "    #df1.drop('Embarked_U', axis=1, inplace=True)\n",
    "    #df2.drop('Embarked_U', axis=1, inplace=True)\n",
    "\n",
    "    return df1,df2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = encode(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection\n",
    "K=12\n",
    "\n",
    "#draw a graph before\n",
    "predictors=df_train.columns.tolist()\n",
    "#selector = SelectKBest(f_classif, k='all')\n",
    "selector = SelectKBest(chi2, k='all')\n",
    "_=selector.fit(df_train, df_y)\n",
    "plt.bar(range(len(predictors)), selector.scores_)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.title('features - before')\n",
    "plt.show()\n",
    "\n",
    "# select K best features\n",
    "\n",
    "selector = SelectKBest(f_classif, k=K)\n",
    "X_train_pruned=selector.fit_transform(df_train, df_y)\n",
    "X_test_pruned=selector.transform(df_test)  \n",
    "\n",
    "selected_features=df_train.columns[selector.get_support(indices=True)].tolist()\n",
    "removed_features=[x for x in predictors if x not in selected_features]\n",
    "print(f'selected: {selected_features}')\n",
    "print(f'removed: {removed_features}')\n",
    "\n",
    "#draw a graph after\n",
    "selector = SelectKBest(chi2, k='all')\n",
    "_=selector.fit(X_train_pruned, df_y)\n",
    "plt.bar(range(len(selected_features)), selector.scores_)\n",
    "plt.xticks(range(len(selected_features)), selected_features, rotation='vertical')\n",
    "plt.title('features - after')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pruned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building autokeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation\n",
    "# X_train,X_val,y_train,y_val=train_test_split(df_train.values,dfy.values,test_size=0.25,random_state=1, shuffle=True)\n",
    "X_train,X_val,y_train,y_val=train_test_split(df_train.values,df_y.values,test_size=0.25,random_state=1, shuffle=True)\n",
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 8)\n",
      "(668,)\n",
      "(223, 8)\n",
      "(223,)\n",
      "(418, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0       2    1  22.0      1      0   7.2500      8         2\n",
       "1       0    0  38.0      1      0  71.2833      2         0\n",
       "2       2    0  26.0      0      0   7.9250      8         2\n",
       "3       0    0  35.0      1      0  53.1000      2         2\n",
       "4       2    1  35.0      0      0   8.0500      8         2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo=np.array(['NUM','CAT','NUM','NUM','CAT','NUM','CAT','CAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQ: ['NUM' 'CAT' 'NUM' 'NUM' 'CAT' 'NUM' 'CAT' 'CAT']\n",
      "QQ1: 0\n",
      "QQ2: 4\n",
      "QQ3: 4\n",
      "num_cat_pair_2: {}\n",
      "0.7453125\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from autokeras.image.image_supervised import ImageClassifier\n",
    "\n",
    "\n",
    "clf = ak.TabularClassifier()\n",
    "clf.fit(X_train, y_train, time_limit=30*60, data_info=datainfo)\n",
    "\n",
    "clf.final_fit(X_train, y_train, X_val, y_val, retrain=True)\n",
    "y = clf.evaluate(X_val, y_val)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TabularClassifier' object has no attribute 'load_searcher'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-760d55a40fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_searcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_auto_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabularClassifier' object has no attribute 'load_searcher'"
     ]
    }
   ],
   "source": [
    "clf.load_searcher().load_best_model().produce_keras_model().save('my_auto_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test data & submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs=clf.predict(X_test)\n",
    "y_preds=np.rint(y_probs).astype(int)\n",
    "y_preds=y_preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test_dataset['PassengerId'],'Survived':y_preds})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
